{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "To begin working on our project, the first thing we need to do is load our data. The data is located in a file called `train.csv` in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: It is considered good practice to have all your imports in a first cell in your notebook. This makes it\n",
    "# easier to see all the libraries that the project uses, as well as to avoid repeated or unnecessary imports. Add all \n",
    "# your imports in this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the file train_data.csv into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will observe that there is another file called `test_data.csv`. When training a machine learning model, it is necessary to set aside some data for testing the performance of the model. This data must not be used when modeling or exploring. We will come to that later in the course, don't worry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What are the contents of the dataframe? Show the first 10 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sentiment` column tells you if the tweet is positive (1) or negative (0). `text` is just the tweet's text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and visualization\n",
    "\n",
    "Before starting any Machine Learning modeling, you should first _always_ , explore your data. This will not only make you understand the data you are working with, but will also make it easier for modeling later. Think about this:\n",
    "\n",
    "* Simple statistics will surface some of the possible biases your dataset may have: Under-representation of certain groups, skewed distributions, etc.\n",
    "* Visualising distributions can easily help detecting outliers or weird values. This could help you detect, for example, errors during data collection, or bad data quality\n",
    "\n",
    "Let's start with some simple questions about our twiter data, just to get to know what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. How many tweets does the dataset contain?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. How many positive and negative tweets are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What is the proportion of positive tweets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. A picture is worth a thusand words... can you plot the distribution of positive/negtives?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What are your thougts on the distribution of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use some domain knowledge to check data quality. We know that tweets cannot be longer than 140 characters. Let's plot the distribution of tweet length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Add a column `text_length_chars` to the dataframe. For each row, this column should tell the length \n",
    "# in characters of the tweet in that row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. What is the minimum, max and average length of a tweet in this dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be something wrong, right? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. How many tweets are over 140 characters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Those are quite a few... print 10 random ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. How does the longest one look like?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of wrong data collection/format. The CSV file was supposed to have two columns only: `sentiment` and `text`, but for some rows in the CSV, they contained an extra column `Sentiment140`. This is most probably a mistake when building the dataset. A quick Google search tells us that `Sentiment140` is [a tool for twitter sentiment anlysis](http://help.sentiment140.com/home). Probably, the dataset was partly collected there.\n",
    "\n",
    "The rest of the tweets with a length greater than 140 are not as extreme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Create a histogram showing the distribution of tweet length for those tweets greater than 140 characters only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the histogrm is extremely skewed, and only that formatting error makes up for the long tail.\n",
    "\n",
    "**Q)** Why do you think that there are still tweets longer than 140 characters? Do you think they are valid?\n",
    "\n",
    "_Tip_: Print some of those tweets and see what's there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Since we have a lot of tweets, and for the sake of simplicity, let's remove all tweets from our dataset with \n",
    "# length greater than 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Plot again a histogram of the tweet length distribution, how does it look now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Do you observe a particular shape? anything surprising?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same analysis for length _in words_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Create a column `text_n_words`. Consider that words are separated by spaces in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. What is the minimum, max and average number of words in a tweet in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Plot a histogram of the length in words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Let's now see if these distributions are similar for positives or negative tweets. Make tow histograms for the\n",
    "# lengths (characters and words), distinguishing between positive and negative tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Are the distributions different? What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Let's now move on to the content. Answer the following questions consider the whole dataset when answering them\n",
    "\n",
    "# How many different words are there in the dataset?\n",
    "# What are the top 100 words?\n",
    "# Plot the distribution of word counts (frequencies) for the first 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. What can you say about the top 100 words and their frequency?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What now?\n",
    "\n",
    "You've gotten to know your data. By now you know:\n",
    "\n",
    "* How big is your dataset\n",
    "* How your positives/negatives are distributed\n",
    "* How long are the tweets, and what are the most common tweet length\n",
    "* What are the most common words in the tweets\n",
    "* How are frequesncies of words distributed\n",
    "\n",
    "In the next part of the preoject, we will learn about how to pre-process data for text analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
